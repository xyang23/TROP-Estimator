---
title: "DWCP_Simulation_Design_CPS"
output: html_notebook
---

To begin we will import the necessary libraries to replicate the code from Python to R. Ensure all packages are installed before attempting to run the file.
```{r}
pck <- c("Matrix", "CVXR", "data.table", "ggplot2", "parallel", "synthdid", "caret", "MASS")
lapply(pck, library, character.only = TRUE) 
```
We begin by replicating the decomposition functions. The order of the functions is changed for accessibility.
```{r}
decompose_Y <- function(Y, rank = 4) {
  N <- nrow(Y)
  T <- ncol(Y)
  
  # Perform Singular Value Decomposition
  svd_result <- svd(Y)
  u <- svd_result$u
  s <- svd_result$d
  v <- svd_result$v
  
  # Extract the rank components
  factor_unit <- u[, 1:rank]
  factor_time <- t(v)[1:rank, ]
  
  # Calculate the low-rank approximation matrix L
  L <- factor_unit %*% diag(s[1:rank]) %*% factor_time
  
  # Calculate the residual matrix E
  E <- Y - L
  
  # Calculate F and M matrices
  F <- outer(rowMeans(L), colMeans(L), `+`) - mean(L)
  M <- L - F
  
  # Return the results
  list(F = F, M = M, E = E, factor_unit_scaled = factor_unit * sqrt(N))
}
```
Now we include the helper functions needed for run_MCNNM
```{r}
getPO <- function(A, O) {
  # Create an output matrix initialized to zeros with the same dimensions as A
  A_out <- matrix(0, nrow = nrow(A), ncol = ncol(A))
  
  # Use the indices in O to copy elements from A to A_out
  A_out[cbind(O[,1], O[,2])] <- A[cbind(O[,1], O[,2])]
  
  return(A_out)
}

getPOinv <- function(A, O) {
  # Create a copy of A to modify
  A_out <- A
  
  # Set elements at specified indices in O to 0
  A_out[cbind(O[,1], O[,2])] <- 0
  
  return(A_out)
}

shrink_lambda <- function(A, lambd) {
  # Perform Singular Value Decomposition
  svd_result <- svd(A)
  S <- svd_result$u
  Σ <- svd_result$d
  R <- t(svd_result$v)
  
  # Shrink the singular values by lambda
  Σ <- Σ - lambd
  Σ[Σ < 0] <- 0
  
  # Reconstruct the matrix with the modified singular values
  S %*% diag(Σ) %*% R
}

```
With the helper functions now defined we can write out the function run_MCNNM
```{r}
run_MCNNM <- function(Y_obs, O, lambd = 10, threshold = 0.01, print_every = NULL, max_iters = 20000) {
  
  # Initialize L_prev with values from Y_obs outside the observed entries
  L_prev <- getPOinv(Y_obs, O)
  change <- 1000
  iters <- 0
  
  while ((change > threshold) && (iters < max_iters)) {
    
    # Get observed and unobserved parts
    PO <- getPO(Y_obs, O)
    PO_inv <- getPOinv(L_prev, O)
    
    # Update L_star and shrink the matrix
    L_star <- PO + PO_inv
    L_new <- shrink_lambda(L_star, lambd)
    
    # Calculate the change
    change <- norm(L_prev - L_new, type = "F")
    
    # Update L_prev and iteration count
    L_prev <- L_new
    iters <- iters + 1
    
    # Print progress if requested
    if (!is.null(print_every) && (iters %% print_every == 0)) {
      cat("Iteration:", iters, "Change:", change, "\n")
    }
  }
  
  return(L_new)
}
```


Below is the cell corresponding to the DWCP_TWFE_average 
```{r}
DWCP_TWFE_average <- function(Y, W, treated_units, lambda_unit, lambda_time, lambda_nn, treated_periods = 10) {
  
  library(CVXR)
  
  N <- nrow(Y)
  T <- ncol(Y)
  
  # dist_time
  dist_time <- abs(1:T - (T - treated_periods / 2))
  
  # dist_unit
  average_treated <- rowMeans(Y[treated_units, , drop = FALSE])
  mask <- matrix(1, N, T)
  mask[, (T - treated_periods + 1):T] <- 0
  A <- rowSums((Y - matrix(average_treated, nrow = N, ncol = T, byrow = TRUE))^2 * mask)
  B <- rowSums(mask)
  dist_unit <- sqrt(A / B)
  
  # distance-based weights
  delta_unit <- exp(-lambda_unit * dist_unit)
  delta_time <- exp(-lambda_time * dist_time)
  delta <- outer(delta_unit, delta_time)
  
  # CVXR variables
  unit_effects <- Variable(1, N)
  time_effects <- Variable(1, T)
  mu <- Variable()
  tau <- Variable()
  L <- Variable(N, T)
  
  unit_factor <- kronecker(matrix(1, T, 1), t(unit_effects))
  time_factor <- kronecker(matrix(1, N, 1), time_effects)
  
  # Objective function
  if (lambda_nn == Inf) {
    objective <- sum_squares((Y - mu - unit_factor - time_factor - L - W * tau) * delta)
  } else {
    objective <- sum_squares((Y - mu - unit_factor - time_factor - L - W * tau) * delta) + lambda_nn * norm(L, "nuc")
  }
  
  # Constraints
  constraints <- list()
  
  # Problem setup and solve
  prob <- Problem(Minimize(objective), constraints)
  result <- solve(prob)
  
  return(result$getValue(tau))
}
```
Below we will implement the cross validation procedure
```{r}
get_CV_score <- function(Y_obs, O, lambd, n_folds = 4, verbose = FALSE) {
  
  # Initialize K-fold cross-validation
  folds <- createFolds(1:nrow(O), k = n_folds, list = TRUE)
  
  mse <- 0
  for (i in seq_along(folds)) {
    Otr_idx <- folds[[i]]
    Otst_idx <- setdiff(1:nrow(O), Otr_idx)
    
    Otr <- O[Otr_idx, , drop = FALSE]
    Otst <- O[Otst_idx, , drop = FALSE]
    
    if (verbose) cat(".")

    L <- run_MCNNM(Y_obs, Otr, lambd, threshold = 1e-10, print_every = NULL, max_iters = 20000)
    
    # Calculate mean squared error for the test set
    mse <- mse + sum((Y_obs[Otst] - L[Otst]) ^ 2)
  }
  
  # Return the average MSE over all folds
  return(mse / n_folds)
}

```
Now that we have the helper function we can implement the fucntion for performing the CV
```{r}
do_CV <- function(Y_obs, O, lambdas = c(5, 10, 20, 40), n_tries = 10, verbose = FALSE) {
  
  score <- list()
  
  for (t in seq_len(n_tries)) {
    run_score <- list()
    for (l in lambdas) {
      if (verbose) cat(sprintf("lambda %d:", l))
      run_score[[as.character(l)]] <- get_CV_score(Y_obs, O, l, n_folds = 4, verbose = verbose)
      if (verbose) cat(sprintf(" : %f\n", run_score[[as.character(l)]]))
    }
    score[[as.character(t)]] <- run_score
  }
  
  return(score)
}

```


For smoothness of code we define helper functions to calculate the unit and time based weights
```{r}
# Define distance functions
dist_time <- function(s, T, T_treat) {
  abs(s - (T - T_treat / 2))
}

dist_unit <- function(j, Y, W, N_treat, T, T_treat) {
  untreated_time <- 1:(T - T_treat)
  Y_j_untreated <- mean(Y[j, untreated_time])
  Y_treated_avg <- mean(Y[(N - N_treat + 1):N, untreated_time])

  squared_diffs <- sum((Y[j, untreated_time] - Y_treated_avg)^2)
  sqrt(squared_diffs / (T - T_treat))
}

# Define weight calculation
calculate_weights <- function(lambda_time, lambda_unit, Y, W, N_treat, T, T_treat) {
  weights <- matrix(0, nrow = nrow(Y), ncol = ncol(Y))
  for (j in 1:nrow(Y)) {
    for (s in 1:ncol(Y)) {
      if (W[j, s] == 0) {
        time_dist <- dist_time(s, T, T_treat)
        unit_dist <- dist_unit(j, Y, W, N_treat, T, T_treat)
        weights[j, s] <- exp(-lambda_time * time_dist - lambda_unit * unit_dist)
      }
    }
  }
  weights
}
```

Objective Function
```{r}
# Objective function
objective <- function(params, Y, W, weights, placebo_units, lambda_nn) {
  tau <- params[1]
  mu <- params[2]
  alpha <- params[3]
  beta <- params[4]
  L <- matrix(params[-(1:4)], nrow = nrow(Y), ncol = ncol(Y))

  W_placebo <- W
  W_placebo[placebo_units, (ncol(W) - T_treat + 1):ncol(W)] <- 1
  
  residuals <- weights * ((Y - (mu + alpha + beta + L - W_placebo * tau))^2)
  penalty <- lambda_nn * norm(L, "F")
  sum(residuals) + penalty
}
```

The new cross validation procedure
```{r}
# Cross-validation function
cross_validation <- function(Y, W, lambda_grid, num_runs = 500) {
  N <- nrow(Y)
  T <- ncol(Y)
  
  N_treat <- nrow(W)
  T_treat <- ncol(W)
  
  best_lambda <- NULL
  best_std_dev <- Inf

  for (lambda_time in lambda_grid) {
    for (lambda_unit in lambda_grid) {
      for (lambda_nn in lambda_grid) {
        weights <- calculate_weights(lambda_time, lambda_unit, Y, W, N_treat, T, T_treat)
        aate_estimates <- numeric(num_runs)
        
        for (run in 1:num_runs) {
          control_units <- which(rowSums(W) == 0)
          placebo_units <- sample(control_units, N_treat, replace = FALSE)

          init_params <- c(0, 0, 0, 0, rep(0, length(Y)))
          result <- optim(init_params, fn = objective, Y = Y, W = W, weights = weights,
                          placebo_units = placebo_units, lambda_nn = lambda_nn)

          if (result$convergence == 0) {
            ate_estimates[run] <- result$value
          }
        }

        std_dev <- sd(ate_estimates)
        if (std_dev < best_std_dev) {
          best_std_dev <- std_dev
          best_lambda <- c(lambda_time, lambda_unit, lambda_nn)
        }
      }
    }
  }
  list(best_lambda = best_lambda, best_std_dev = best_std_dev)
}

```

